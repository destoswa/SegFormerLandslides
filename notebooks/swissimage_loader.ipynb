{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e330343",
   "metadata": {},
   "source": [
    "# SWISSIMAGE loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305ea7bc",
   "metadata": {},
   "source": [
    "1) [Production of extents](#production-of-extents) \\\n",
    "    1.1) [Loading and data visualization](#loading-and-data-visualization) \\\n",
    "    1.2) [Add flight_year to points](#add-flight_year-to-points) \\\n",
    "    1.2) [Add flight_year to merged polygons](#add-flight_year-to-merged-polygons) \n",
    "2) [Processing of extents](#processing-of-extents) \\\n",
    "    2.1) [Binarization of masks](#binarization-of-masks) \\\n",
    "    2.2) [Splitting images into 512x512 subset](#splitting-images-into-512x512-subset) \\\n",
    "    2.3) [Remove tiles that don't contain landslides](#remove-tiles-that-dont-contain-landslides) \\\n",
    "    2.4) [Sort into subfolders](#sort-into-subfolders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67deb97c",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bee5dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d09d5",
   "metadata": {},
   "source": [
    "## Production of extents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e5b9d",
   "metadata": {},
   "source": [
    "### Loading and data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33a08939",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_polygons = r\"D:\\Terranum_SD\\99_Data\\Landslide\\data\\Bern_glissements_spontane_shpfiles\\BD glissements spontanés\\BE_SL_all_aggreg_PQ.shp\"\n",
    "src_points_intersect = r\"D:\\Terranum_SD\\99_Data\\Landslide\\data\\Bern_glissements_spontane_shpfiles\\points_landslide_bern_intersect_polygons.gpkg\"\n",
    "src_km_grid = r\"D:\\Terranum_SD\\99_Data\\Landslide\\data\\Bern_glissements_spontane_shpfiles\\swissIMAGE_HIST.gpkg\"\n",
    "src_landslides_merged = r\"D:\\Terranum_SD\\99_Data\\Landslide\\data\\Bern_glissements_spontane_shpfiles\\landslides_anriss_auslauf_merged.gpkg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aa2ba925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of years:  24\n",
      "[1962 1974 1980 1985 1992 1993 1998 1999 2000 2004 2005 2006 2007 2008\n",
      " 2009 2010 2012 2014 2015 2016 2017 2018 2021 2022]\n",
      "Index(['RS_ID', 'year', 'outline', 'source', 'ID_alt', 'Anrissmäc', 'Volumen',\n",
      "       'ID', 'Jahr', 'Datum', 'SHAPE_Leng', 'SHAPE_Area', 'geometry',\n",
      "       'flight_year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "points_intersect = gpd.read_file(src_points_intersect)\n",
    "print(\"Number of years: \", len(points_intersect.year.unique()))\n",
    "print(np.sort(points_intersect.year.unique()))\n",
    "points_intersect['flight_year'] = np.zeros(len(points_intersect))\n",
    "print(points_intersect.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce46d146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         flight_year resolution_of_origin  \\\n",
      "0  1926,1943,1946,1954,1969,1975,1976,1981,1987,1...        50,100,,25,10   \n",
      "1  1926,1943,1946,1954,1955,1956,1969,1975,1976,1...        50,100,,25,10   \n",
      "2  1926,1943,1946,1955,1956,1969,1975,1976,1981,1...        50,100,,25,10   \n",
      "3  1926,1931,1946,1951,1962,1965,1969,1971,1975,1...        50,100,,25,10   \n",
      "4  1926,1943,1946,1955,1956,1969,1975,1976,1981,1...        50,100,,25,10   \n",
      "\n",
      "      id     left      top    right   bottom  \\\n",
      "0  45727  2670000  1206000  2671000  1205000   \n",
      "1  46200  2672000  1201000  2673000  1200000   \n",
      "2  46201  2672000  1200000  2673000  1199000   \n",
      "3  45024  2667000  1207000  2668000  1206000   \n",
      "4  46202  2672000  1199000  2673000  1198000   \n",
      "\n",
      "                                            geometry  \n",
      "0  MULTIPOLYGON (((2670601.819 1206000, 2671000 1...  \n",
      "1  MULTIPOLYGON (((2672000 1201000, 2673000 12010...  \n",
      "2  MULTIPOLYGON (((2672000 1199083.191, 2672000 1...  \n",
      "3  MULTIPOLYGON (((2667000 1206947.07, 2667000 12...  \n",
      "4  MULTIPOLYGON (((2673000 1199000, 2673000 11988...  \n",
      "0        1926,1943,1946,1954,1969,1975,1976,1981,1987,1...\n",
      "1        1926,1943,1946,1954,1955,1956,1969,1975,1976,1...\n",
      "2        1926,1943,1946,1955,1956,1969,1975,1976,1981,1...\n",
      "3        1926,1931,1946,1951,1962,1965,1969,1971,1975,1...\n",
      "4        1926,1943,1946,1955,1956,1969,1975,1976,1981,1...\n",
      "                               ...                        \n",
      "58504                                                 2008\n",
      "58505                                                 2008\n",
      "58506                                                 2008\n",
      "58507                                                 2008\n",
      "58508                                                 2008\n",
      "Name: flight_year, Length: 58509, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# load grid\n",
    "grid = gpd.read_file(src_km_grid)\n",
    "print(grid.head())\n",
    "print(grid.flight_year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771e6a6c",
   "metadata": {},
   "source": [
    "### Add flight_year to points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e592e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 556/556 [00:01<00:00, 332.99it/s]\n"
     ]
    }
   ],
   "source": [
    "lst_points_too_recent = []\n",
    "lst_flight_years = np.zeros(len(points_intersect), dtype=int)\n",
    "for point in tqdm(points_intersect.itertuples(), total=len(points_intersect)):\n",
    "    intersection_mask = grid.geometry.contains(point.geometry)#.intersection(grid.geometry)\n",
    "    intersection = grid[intersection_mask]\n",
    "\n",
    "    lst_years = []\n",
    "    if np.sum(intersection_mask) != 1:\n",
    "        print(\"Problem (no matching polygon) with : \", point)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        flight_year = np.min([int(x) for x in intersection.flight_year.values[0].split(',') if int(x) > point.year])\n",
    "    except:\n",
    "        lst_points_too_recent.append(point)\n",
    "        continue\n",
    "\n",
    "    lst_flight_years[point.Index] = flight_year\n",
    "\n",
    "points_intersect['flight_year'] = lst_flight_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e721041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points with year too high for the grid:  16\n",
      "Different flight years:  {0, 1968, 1974, 1980, 1985, 1992, 1993, 1998, 1999, 2000, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2015, 2016, 2018, 2021}\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of points with year too high for the grid: \", np.sum(lst_flight_years == 0))\n",
    "print(\"Different flight years: \", set(points_intersect.flight_year.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb46fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_intersect.to_file(src_points_intersect.split('.gpkg')[0] + '_w_flight_year.gpkg', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6f6bb2",
   "metadata": {},
   "source": [
    "### Add flight_year to merged polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7dcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 44/498 [00:00<00:02, 213.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2010, 2021]\n",
      "2010\n",
      "[2004, 1999]\n",
      "1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 113/498 [00:00<00:01, 224.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2004, 1998]\n",
      "1998\n",
      "[1999, 2007]\n",
      "1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 183/498 [00:00<00:01, 225.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016, 2004]\n",
      "2004\n",
      "[2004, 2007]\n",
      "2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 276/498 [00:01<00:00, 225.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2007, 2004]\n",
      "2004\n",
      "[2018, 2004, 2004]\n",
      "2004\n",
      "[2004, 2005]\n",
      "2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 345/498 [00:01<00:00, 223.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2007, 2004, 2007]\n",
      "2007\n",
      "[1998, 2007]\n",
      "1998\n",
      "[2004, 2018]\n",
      "2004\n",
      "[2015, 2018]\n",
      "2015\n",
      "[2012, 2009]\n",
      "2009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 414/498 [00:01<00:00, 220.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2006, 2009, 2015, 2015]\n",
      "2015\n",
      "[2006, 2015]\n",
      "2006\n",
      "[2015, 2018]\n",
      "2015\n",
      "[2004, 2015]\n",
      "2004\n",
      "[2012, 2012, 2015]\n",
      "2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 498/498 [00:02<00:00, 220.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2004, 2004, 2000]\n",
      "2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "merged_polygons = gpd.read_file(src_landslides_merged)\n",
    "# print(merged_polygons.index)points_intersect = gpd.read_file(src_points_intersect.split('.gpkg')[0] + '_w_flight_year.gpkg')\n",
    "points_intersect = points_intersect[points_intersect.flight_year >= 1998]\n",
    "flight_year = np.zeros(len(merged_polygons), dtype=int)\n",
    "list_polygons_too_old = []\n",
    "for polygon in tqdm(merged_polygons.itertuples(), total=len(merged_polygons)):\n",
    "    points = [p for p in points_intersect.itertuples() if polygon.geometry.contains(p.geometry)]\n",
    "    flight_years = [x.flight_year for x in points]\n",
    "    if len(set(flight_years)) == 1:\n",
    "        flight_year[polygon.Index] = flight_years[0]\n",
    "    elif len(set(flight_years)) > 1:\n",
    "        flight_year[polygon.Index] = np.bincount(flight_years).argmax()\n",
    "        print([x.flight_year for x in points])\n",
    "        print(flight_year[polygon.Index])\n",
    "    else:\n",
    "        list_polygons_too_old.append(polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f1742c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of polygons too old:  49\n",
      "Different years:  [0, 1998, 1999, 2000, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2015, 2016, 2018, 2021]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of polygons too old: \", len(list_polygons_too_old))\n",
    "print(\"Different years: \", sorted(set(merged_polygons.flight_year)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f869e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_polygons['flight_year'] = flight_year\n",
    "merged_polygons.to_file(src_landslides_merged.split('.gpkg')[0] + \"_w_flight_year.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d164e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88b223ff",
   "metadata": {},
   "source": [
    "## Processing of extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8714fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data = r\"D:\\Terranum_SD\\99_Data\\Landslide\\data\\Bern_glissements_spontane_shpfiles\\Extents\"\n",
    "src_tiles = r\"D:\\Terranum_SD\\99_Data\\Landslide\\data\\Bern_glissements_spontane_shpfiles\\Extents\\tiles\"\n",
    "src_no_landslide = os.path.join(src_tiles, \"no_landslide\")\n",
    "src_images = os.path.join(src_tiles, 'images')\n",
    "src_masks = os.path.join(src_tiles, 'labels')\n",
    "src_masks_bin = os.path.join(src_tiles, 'masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818b758",
   "metadata": {},
   "source": [
    "### Binarization of masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96fc2fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_images_to_process = [os.path.join(src_data, x) for x in os.listdir(src_data) if x.split('.')[-1].lower() in ['png','jpg','jpeg'] and 'mask_bin' not in x]\n",
    "list_masks = [x for x in list_images_to_process if 'mask' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d3e9695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:26<00:00, 16.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for _, mask in tqdm(enumerate(list_masks),total=len(list_masks)):\n",
    "    img  = Image.open(mask)\n",
    "    img_arr = np.array(img)\n",
    "    img_arr_rgb = img_arr[..., 0:3]\n",
    "    img_bin = np.sum(img_arr_rgb, axis=2)\n",
    "    img_bin[img_bin != 0] = 1\n",
    "    result = Image.fromarray(img_bin.astype(np.uint8))\n",
    "    result_src = ''.join(mask.replace(\"mask\", \"bin\").split('.')[0:-1]) + '.tif'\n",
    "    result.save(result_src)\n",
    "    list_images_to_process.append(result_src)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71468b71",
   "metadata": {},
   "source": [
    "### Splitting images into 512x512 subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c790824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_image_overlap(in_path, tile_size=512, overlap=0, save_dir=None, verbose=False):\n",
    "    save_dir = os.path.join(os.path.dirname(in_path), 'tiles') if save_dir == None else save_dir\n",
    "    ext = in_path.split('.')[-1]\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    img = Image.open(in_path)\n",
    "    w, h = img.size\n",
    "\n",
    "    tile_id = 0\n",
    "    for y in range(0, h, tile_size):\n",
    "        for x in range(0, w, tile_size):\n",
    "            # manage if borders reached\n",
    "            if x + tile_size > w:\n",
    "                x = w - tile_size\n",
    "            if y + tile_size > h:\n",
    "                y = h - tile_size\n",
    "\n",
    "            # Crop region (handles border tiles automatically)\n",
    "            tile = img.crop((x, y, x + tile_size, y + tile_size))\n",
    "            output_path = os.path.join(save_dir, ''.join(os.path.basename(in_path).split('.')[:-1]) + f\"_{tile_id}.tif\")\n",
    "            tile.save(output_path)\n",
    "            tile_id += 1\n",
    "    if verbose:\n",
    "        print(f\"Saved {tile_id} overlapping tiles.\")\n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c1d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [00:04<00:00, 110.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of created tiles:  4685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_samples = 0\n",
    "# temp_list = [os.path.join(src_data, x) for x in os.listdir(src_data) if x.endswith('tif')]\n",
    "for _ ,image in tqdm(enumerate(list_images_to_process), total=len(list_images_to_process)):\n",
    "    num_samples += tile_image_overlap(image)\n",
    "\n",
    "print(\"Number of created tiles: \", num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7280238a",
   "metadata": {},
   "source": [
    "### Remove tiles that don't contain landslides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ae633",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_masks = [os.path.join(src_tiles, x) for x in os.listdir(src_tiles) if 'mask' in x and not 'bin' in x]\n",
    "list_masks_bin = [os.path.join(src_tiles, x) for x in os.listdir(src_tiles) if 'mask_bin' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dacf23ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of masks:  4685\n",
      "Number of masks bin:  4685\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Number of masks: \", len(list_masks))\n",
    "print(\"Number of masks bin: \", len(list_masks_bin))\n",
    "# assert len(list_masks) == len(list_masks_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b7499ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_no_correspondance = []\n",
    "for mask in list_masks:\n",
    "    if not os.path.exists(mask.replace('mask', 'image')):\n",
    "        lst_no_correspondance.append(mask)\n",
    "if len(lst_no_correspondance) > 0:\n",
    "    print(\"The following masks don't have corresponding image:\")\n",
    "    for x in lst_no_correspondance:\n",
    "        print(f\"\\t{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddcfc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4685/4685 [02:30<00:00, 31.09it/s]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(src_no_landslide, exist_ok=True)\n",
    "\n",
    "for _, mask_bin in tqdm(enumerate(list_masks_bin), total=len(list_masks_bin)):\n",
    "    img = Image.open(mask_bin)\n",
    "    img_arr = np.array(img)\n",
    "    # img_arr_rgb = img_arr[...,0:3]\n",
    "    # img_arr_rgb[img_arr_rgb != 0] = 1\n",
    "    assert set(img_arr.flatten()) in [{0}, {1}, {0, 1}]\n",
    "    img.close()\n",
    "    if set(img_arr.flatten()) == {0}:\n",
    "        # mask = [x for x in list_masks if x.split('.')[0].replace('mask', 'mask_bin') in mask_bin][0]\n",
    "        mask = mask_bin.replace('_bin', '').replace('tif', 'png')\n",
    "        image = mask.replace('mask', 'image')\n",
    "        os.rename(mask_bin, os.path.join(src_no_landslide, os.path.basename(mask_bin)))\n",
    "        os.rename(mask, os.path.join(src_no_landslide, os.path.basename(mask)))\n",
    "        os.rename(image, os.path.join(src_no_landslide, os.path.basename(image)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808c275f",
   "metadata": {},
   "source": [
    "### Sort into subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aacffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(src_images, exist_ok=True)\n",
    "os.makedirs(src_masks, exist_ok=True)\n",
    "os.makedirs(src_masks_bin, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fefd259c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "list_tiles = [os.path.join(src_tiles, x) for x in os.listdir(src_tiles) if not os.path.isdir(os.path.join(src_tiles,x))]\n",
    "\n",
    "print(len(list_tiles))\n",
    "\n",
    "for _, tile_src in tqdm(enumerate(list_tiles), total=len(list_tiles)):\n",
    "    if 'image' in tile_src:\n",
    "        os.rename(tile_src, os.path.join(src_images, os.path.basename(tile_src).replace('image_', '')))\n",
    "    elif 'mask' in tile_src:\n",
    "        os.rename(tile_src, os.path.join(src_masks, os.path.basename(tile_src).replace('mask_', '')))\n",
    "    elif 'bin' in tile_src:\n",
    "        os.rename(tile_src, os.path.join(src_masks_bin, os.path.basename(tile_src).replace('bin_', '')))\n",
    "    else:\n",
    "        print(f\"No category for: {tile_src}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ba0cb",
   "metadata": {},
   "source": [
    "# Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52390371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1124\n"
     ]
    }
   ],
   "source": [
    "list_masks_bin = [os.path.join(src_no_landslide, x) for x in os.listdir(src_no_landslide) if \"mask_bin\" in x and x.endswith('.tif')]\n",
    "print(len(list_masks_bin))\n",
    "for mask in list_masks_bin:\n",
    "    os.rename(mask, mask.replace('mask_bin', 'bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4af55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2248/2248 [00:27<00:00, 82.36it/s] \n"
     ]
    }
   ],
   "source": [
    "list_img = [os.path.join(src_no_landslide, x) for x in os.listdir(src_no_landslide) if not os.path.isdir(os.path.join(src_no_landslide,x)) and \".tif\" not in x]\n",
    "print(len(list_img))\n",
    "for _, img_src in tqdm(enumerate(list_img), total=len(list_img)):\n",
    "    img = Image.open(img_src)\n",
    "    img.save(''.join(img_src.split('.')[:-1]) + '.tif')\n",
    "    os.remove(img_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a141bdec",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
